{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools, csv, ast\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"Helge_code\"\n",
    "inMigration_file = \"Sudan_states_inmigration_2023-10-12.csv\"\n",
    "outMigration_file = \"Sudan_states_outmigration_2023-10-12.csv\"\n",
    "\n",
    "with open(os.path.join(dir, inMigration_file),\"r\") as f1, \\\n",
    "    open(os.path.join(dir, outMigration_file),\"r\") as f2:\n",
    "    in_m = pd.read_csv(f1).rename(columns={\"to\":\"location\"})\n",
    "    out_m = pd.read_csv(f2).rename(columns={\"from\":\"location\"})\n",
    "in_m[\"date_later\"] = pd.to_datetime(in_m[\"date_later\"])\n",
    "out_m[\"date_later\"] = pd.to_datetime(out_m[\"date_later\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_delta_dev = 5\n",
    "time_deltas = [i for i in range(-1*abs(time_delta_dev),abs(time_delta_dev)+1)]\n",
    "\n",
    "def time_shift(df, td, date_col = \"date_later\", val_col = \"val\", loc_col = \"location\"):\n",
    "    dates = list(df[date_col].unique())\n",
    "    def shift(date):\n",
    "        if dates.index(date)+td < 0 or dates.index(date)+td >= len(dates):\n",
    "            return \"08/11/2024\"\n",
    "        else:\n",
    "            return dates[dates.index(date)+td]\n",
    "\n",
    "    left = df[[date_col,val_col,loc_col]].copy()\n",
    "    right = df[[elem for elem in df.columns if elem!=val_col]].copy()\n",
    "    right[date_col] = pd.to_datetime(right[date_col].apply(shift))\n",
    "    return pd.merge(left, right, on = [date_col,loc_col], how = \"inner\").drop(columns = [date_col,loc_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_0_rows(df):\n",
    "    return df[~(df[df.columns[2:]] == 0).all(axis=1)]\n",
    "\n",
    "if True:\n",
    "    in_m = rm_0_rows(in_m)\n",
    "    out_m = rm_0_rows(out_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "correlations:   2%|‚ñè         | 199/12540 [00:28<29:29,  6.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rpi11/Desktop/Code/MDI/fall_23/forced-movement/Fm_Emotion/Arabic/FALL/compare.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rpi11/Desktop/Code/MDI/fall_23/forced-movement/Fm_Emotion/Arabic/FALL/compare.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m prog_bar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rpi11/Desktop/Code/MDI/fall_23/forced-movement/Fm_Emotion/Arabic/FALL/compare.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m rfe \u001b[39m=\u001b[39m RFE(model, n_features_to_select\u001b[39m=\u001b[39mvar_num)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rpi11/Desktop/Code/MDI/fall_23/forced-movement/Fm_Emotion/Arabic/FALL/compare.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m rfe\u001b[39m.\u001b[39mfit(X,Y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rpi11/Desktop/Code/MDI/fall_23/forced-movement/Fm_Emotion/Arabic/FALL/compare.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m relevant_features \u001b[39m=\u001b[39m rfe\u001b[39m.\u001b[39msupport_\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rpi11/Desktop/Code/MDI/fall_23/forced-movement/Fm_Emotion/Arabic/FALL/compare.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m X_fit \u001b[39m=\u001b[39m X[X\u001b[39m.\u001b[39mcolumns[relevant_features]]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/feature_selection/_rfe.py:251\u001b[0m, in \u001b[0;36mRFE.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 251\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/feature_selection/_rfe.py:299\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    297\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting estimator with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m features.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m np\u001b[39m.\u001b[39msum(support_))\n\u001b[0;32m--> 299\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X[:, features], y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    301\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m    302\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    303\u001b[0m     estimator,\n\u001b[1;32m    304\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimportance_getter,\n\u001b[1;32m    305\u001b[0m     transform_func\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:656\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39maccept_sparse, y_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    650\u001b[0m )\n\u001b[1;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    654\u001b[0m )\n\u001b[0;32m--> 656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[1;32m    657\u001b[0m     X,\n\u001b[1;32m    658\u001b[0m     y,\n\u001b[1;32m    659\u001b[0m     fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m    660\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_X,\n\u001b[1;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    662\u001b[0m )\n\u001b[1;32m    664\u001b[0m \u001b[39m# Sample weight can be implemented via a simple rescaling.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m X, y, sample_weight_sqrt \u001b[39m=\u001b[39m _rescale_data(X, y, sample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:230\u001b[0m, in \u001b[0;36m_preprocess_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    227\u001b[0m     sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(sample_weight)\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m--> 230\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, copy\u001b[39m=\u001b[39;49mcopy, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES)\n\u001b[1;32m    231\u001b[0m \u001b[39melif\u001b[39;00m copy:\n\u001b[1;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# error message.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(over\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     first_pass_isfinite \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39misfinite(xp\u001b[39m.\u001b[39;49msum(X))\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2296\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2298\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2299\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_covars = list(in_m.columns[3:])\n",
    "\n",
    "df_types = [(\"IN\",in_m),(\"OUT\",out_m)]\n",
    "locations = [\"all\"] + list(in_m[\"location\"].unique())\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "k_features = 10\n",
    "\n",
    "length = 2*3*len(locations)*len(time_deltas)*k_features\n",
    "prog_bar = tqdm(total = length, desc = \"correlations\")\n",
    "\n",
    "cat_corrs = \"correlations/cat_corrs.csv\"\n",
    "with open(cat_corrs, \"w+\") as o:\n",
    "    writer = csv.writer(o)\n",
    "\n",
    "    header = [\"migration\",\"indicator\",\"location\",\"time_shift (time chunk)\",\n",
    "              \"n\",\"var_num\",\"covars\",\"R^2\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for df_type in df_types:\n",
    "        name = df_type[0]\n",
    "        df = df_type[1]\n",
    "\n",
    "        constant_cols = [\"val\",\"date_later\",\"location\"]\n",
    "        df_all = df.copy()\n",
    "        df_emo = df[constant_cols + [c for c in df.columns[3:] if \"sentiment\" not in c]].copy()\n",
    "        df_senti = df[constant_cols + [c for c in df.columns[3:] if \"sentiment\" in c]].copy()\n",
    "\n",
    "        for cat, data in zip([\"all\",\"emo\",\"senti\"],[df_all, df_emo, df_senti]):\n",
    "            for loc in locations:\n",
    "                data_loc = data[data[\"location\"]==loc] if loc != \"all\" else data.copy()\n",
    "\n",
    "                for td in time_deltas:\n",
    "                    data_loc_td = time_shift(data_loc, td)\n",
    "                    if len(data_loc_td) == 0:\n",
    "                        continue\n",
    "\n",
    "                    X = data_loc_td[data_loc_td.columns[1:]]\n",
    "                    Y = data_loc_td[\"val\"]\n",
    "\n",
    "                    for var_num in range(1,min(X.shape[1], k_features)):\n",
    "                        prog_bar.update(1)\n",
    "\n",
    "                        rfe = RFE(model, n_features_to_select=var_num)\n",
    "                        rfe.fit(X,Y)\n",
    "                        relevant_features = rfe.support_\n",
    "                        X_fit = X[X.columns[relevant_features]]\n",
    "\n",
    "                        model.fit(X_fit,Y)\n",
    "                        r_squared = round(model.score(X_fit,Y), 4)\n",
    "\n",
    "                        row = [name,cat,loc,td,len(data_loc_td),var_num,\n",
    "                               str(list(X_fit.columns)),r_squared]\n",
    "                        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cat_corrs, \"r\") as f:\n",
    "    corrs = pd.read_csv(f)\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_corrs = {}\n",
    "for io in corrs[\"migration\"].unique():\n",
    "    best_corrs[io] = {}\n",
    "    for indic in corrs[\"indicator\"].unique():\n",
    "        best_corrs[io][indic] = {}\n",
    "        for loc in corrs[\"location\"].unique():\n",
    "            subset = corrs[(corrs[\"migration\"] == io) & \\\n",
    "                           (corrs[\"indicator\"] == indic) & \\\n",
    "                            (corrs[\"location\"] == loc)]\n",
    "            \n",
    "            if len(subset) > 0:\n",
    "                row = subset.loc[subset[\"R^2\"].idxmax()]\n",
    "\n",
    "                best_corrs[io][indic][loc] = {\n",
    "                    \"td\":row[\"time_shift (time chunk)\"],\n",
    "                    \"cv\":ast.literal_eval(row[\"covars\"])\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for io in best_corrs:\n",
    "    for indic in best_corrs[io]:\n",
    "        for loc in best_corrs[io][indic]:\n",
    "            print(loc)\n",
    "\n",
    "            if io == \"IN\":\n",
    "                reg_df = in_m.copy()\n",
    "            else:\n",
    "                reg_df = out_m.copy()\n",
    "            \n",
    "            if loc != \"all\":\n",
    "                reg_df = reg_df[reg_df[\"location\"] == loc]\n",
    "            reg_df = reg_df[best_corrs[io][indic][loc][\"cv\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
